# LogitLens4LLMs

LogitLens4LLMs æ˜¯ä¸€ä¸ªç”¨äºç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ Logit Lens å·¥å…·åŒ…ã€‚å®ƒæ”¯æŒå¯¹æ¨¡å‹çš„éšè—çŠ¶æ€å’Œé¢„æµ‹è¿›è¡Œé€å±‚åˆ†æï¼Œç›®å‰æ”¯æŒ Llama-3.1-8B å’Œ Qwen-2.5-7B æ¨¡å‹ã€‚

## åŠŸèƒ½ç‰¹æ€§

- **é€å±‚åˆ†æ**ï¼šé€šè¿‡ Logit Lens æŠ€æœ¯ï¼Œé€å±‚åˆ†ææ¨¡å‹çš„éšè—çŠ¶æ€å’Œé¢„æµ‹ç»“æœã€‚
- **å¤šæ¨¡å‹æ”¯æŒ**ï¼šç›®å‰æ”¯æŒ Llama-3.1-8B å’Œ Qwen-2.5-7B æ¨¡å‹ï¼Œæœªæ¥å°†æ”¯æŒæ›´å¤šæ¨¡å‹ã€‚
- **å¯è§†åŒ–è¾“å‡º**ï¼šç”Ÿæˆçƒ­åŠ›å›¾ï¼Œç›´è§‚å±•ç¤ºæ¯ä¸€å±‚çš„é¢„æµ‹ç»“æœã€‚
- **æœ¬åœ°æ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒä»æœ¬åœ°åŠ è½½æ¨¡å‹ï¼Œå‡å°‘å¯¹ç½‘ç»œçš„ä¾èµ–ã€‚

## æ–‡ä»¶ç»“æ„

```
LogitLens4LLMs/
â”œâ”€â”€ README.md
â”œâ”€â”€ README_zh.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py                    # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ model_factory.py           # æ¨¡å‹å·¥å‚ç±»
â”œâ”€â”€ activation_analyzer.py     # æ¿€æ´»å€¼åˆ†æå™¨
â”œâ”€â”€ model_helper/             # æ¨¡å‹è¾…åŠ©ç±»
â”‚   â”œâ”€â”€ llama_2_helper.py     # Llama-2 æ¨¡å‹è¾…åŠ©ç±»
â”‚   â”œâ”€â”€ llama_3_1_helper.py   # Llama-3.1 æ¨¡å‹è¾…åŠ©ç±»
â”‚   â””â”€â”€ qwen_helper.py        # Qwen æ¨¡å‹è¾…åŠ©ç±»
â”œâ”€â”€ colab_notebook/          # Colab ç¤ºä¾‹ç¬”è®°æœ¬
â”‚   â”œâ”€â”€ logit_lens_Llama_3_1_8b.ipynb  # Llama-3.1-8B ç¤ºä¾‹
â”‚   â””â”€â”€ logit_lens_Qwen_7b.ipynb       # Qwen-7B ç¤ºä¾‹
â””â”€â”€ output/                   # è¾“å‡ºç›®å½•
    â””â”€â”€ visualizations/       # å¯è§†åŒ–ç»“æœ
```

## å¿«é€Ÿå¼€å§‹

### æœ¬åœ°è¿è¡Œ

1. å…‹éš†æœ¬ä»“åº“ï¼š
   ```bash
   git clone https://github.com/zhenyu-02/LogitLens4LLMs
   cd LogitLens4LLMs
   ```

2. å®‰è£…ä¾èµ–ï¼š
   ```bash
   pip install -r requirements.txt
   ```

### Google Colab

æˆ‘ä»¬æä¾›äº† Google Colab ç¬”è®°æœ¬ï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨æµè§ˆå™¨ä¸­è¿è¡Œç¤ºä¾‹ï¼š

- [Llama-3.1-8B Logit Lens åˆ†æ](https://colab.research.google.com/drive/1OcYRKAsVI-me1zmtnhwoQfdyg6y_SVd3?usp=sharing)
- [Qwen-7B Logit Lens åˆ†æ](https://colab.research.google.com/drive/1xpBQSnukiNPka2oQDtLd7sKdQ0gt74PU?usp=sharing)


## ä½¿ç”¨ç¤ºä¾‹

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•å¯¹ Llama-3.1-8B æ¨¡å‹è¿›è¡Œ Logit Lens åˆ†æï¼š

```python
from logit_lens.model_factory import ModelFactory, ModelType

# åˆå§‹åŒ–æ¨¡å‹
model_type = ModelType.LLAMA_3_1_8B
model = ModelFactory.create_model(model_type, use_local=False)

# è¿è¡Œ Logit Lens åˆ†æ
prompt = "Complete this sentence: The cat sat on the"
prediction_steps = model.generate_with_probing(prompt, max_new_tokens=10, print_details=True)

# è¾“å‡ºç»“æœ
for step in prediction_steps:
    print(f"Step {step['step_idx']}: Predicted token: {step['predicted_token']}")
```

### è¾“å‡ºç¤ºä¾‹
å‘½ä»¤è¡Œè¾“å‡ºï¼Œå¯è‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°jsonæ–‡ä»¶
```
Running logit lens analysis:
Model type: llama_3_1_8b
Prompt: Complete this sentence: The cat sat on the

Step 1: Predicted token: " mat"
Current text: Complete this sentence: The cat sat on the mat

Important layers for this prediction:

Layer 15:
  attention_mechanism: [('mat', 85), ('floor', 12), ('carpet', 3)]
  mlp_output: [('mat', 82), ('floor', 15), ('rug', 3)]
  block_output: [('mat', 88), ('floor', 10), ('carpet', 2)]

Layer 20:
  attention_mechanism: [('mat', 90), ('floor', 8), ('rug', 2)]
  block_output: [('mat', 92), ('floor', 7), ('carpet', 1)]
```

## å¯è§†åŒ–è¾“å‡º

è¯¥å·¥å…·ä¼šä¸ºæ¯ä¸ªç”Ÿæˆæ­¥éª¤ç”Ÿæˆä¸¤ç§çƒ­åŠ›å›¾ï¼š

1. é‡è¦å±‚çƒ­åŠ›å›¾ - å±•ç¤ºæ¦‚ç‡é«˜äºé˜ˆå€¼çš„å±‚çš„é¢„æµ‹
2. å…¨å±‚çƒ­åŠ›å›¾ - å±•ç¤ºæ‰€æœ‰å±‚çš„é¢„æµ‹æƒ…å†µ

![ALL Layers Visualization](./output/visualizations/all_layers_step_0.png)

## æ¨¡å‹æ”¯æŒ

ç›®å‰æ”¯æŒçš„æ¨¡å‹åŒ…æ‹¬ï¼š

- **Llama-3.1-8B**
- **Qwen-2.5-7B**
- **Llama-2-7B**

æœªæ¥å°†æ”¯æŒæ›´å¤šæ¨¡å‹ï¼Œæ¬¢è¿è´¡çŒ®ä»£ç ã€‚

## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·å…ˆ fork æœ¬ä»“åº“ï¼Œç„¶åæäº¤ Pull Requestã€‚æˆ‘ä»¬ä¼šåœ¨å®¡æ ¸ååˆå¹¶æ‚¨çš„ä»£ç ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦æƒ…è¯·è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®çš„å¯å‘å’Œæ”¯æŒï¼š

- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Logit Lens](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)
- [Logit Lens for Llama-2](https://www.lesswrong.com/posts/fJE6tscjGRPnK8C2C/decoding-intermediate-activations-in-llama-2-7b)

## è”ç³»æ–¹å¼

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ [zhenyu_wang02@outlook.com](mailto:zhenyu_wang02@outlook.com) è”ç³»æˆ‘ã€‚

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬å·¥å…·ï¼Œè¯·æŒ‰ä»¥ä¸‹æ ¼å¼å¼•ç”¨ï¼š

```bibtex
@software{wang2024logitlens,
  title = {LogitLens4LLMs: A Logit Lens Toolkit for Modern Large Language Models},
  author = {Wang, Zhenyu},
  year = {2025},
  url = {https://github.com/zhenyu-02/LogitLens4LLMs},
  version = {1.0.0},
  date = {2025-02-17}
}
```

æˆ–åœ¨æ–‡ç« ä¸­å¼•ç”¨ï¼š

```
Wang, Z. (2025). LogitLens4LLMs: A Logit Lens Toolkit for Modern Large Language Models (Version 1.0.0) [Computer software]. https://github.com/zhenyu-02/LogitLens4LLMs
```

---

Happy Coding! ğŸš€